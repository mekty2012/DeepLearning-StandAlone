{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "uRVlZq75JUJn",
        "colab_type": "code",
        "outputId": "1e41ff2f-4d57-4eca-efdc-bfa9674b29e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q torch==1.0.0 torchvision\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PD4cIKKvKFCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "29UainWPco7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "Cu753dPPKGkV",
        "colab_type": "code",
        "outputId": "2a8810b5-92d8-4ece-fe9e-c7ee2df693ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=4, \n",
        "                                        shuffle=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RxnfFJwBcsAv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "metadata": {
        "id": "_G6bZbbkMWWt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hid_dim, n_layer, act):\n",
        "        super(MLP, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layer = n_layer\n",
        "        self.act = act\n",
        "        \n",
        "        self.fc = nn.Linear(self.in_dim, self.hid_dim)\n",
        "        self.linears = nn.ModuleList()\n",
        "        \n",
        "        for i in range(self.n_layer-1):\n",
        "            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n",
        "        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n",
        "        \n",
        "        if self.act == 'relu':\n",
        "            self.act = nn.ReLU()\n",
        "          \n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc(x))\n",
        "        for fc in self.linears:\n",
        "            x = self.act(fc(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "      \n",
        "net = MLP(3072, 10, 100, 4, 'relu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itGsp6jDWs_a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Experiment"
      ]
    },
    {
      "metadata": {
        "id": "LiOCP6TqWw2V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def experiment(args):\n",
        "  \n",
        "    net = MLP(args.in_dim, args.out_dim, args.hid_dim, args.n_layer, args.act)\n",
        "    net.cuda()\n",
        "    #print(net)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.mm)\n",
        "    \n",
        "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
        "\n",
        "        # ==== Train ===== #\n",
        "        net.train()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        train_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.view(-1, 3072)\n",
        "            \n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            \n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            train_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                #print('[%d, %5d] loss: %.3f' %\n",
        "                #      (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "                \n",
        "\n",
        "        # ==== Validation ====== #\n",
        "        net.eval()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_loss = 0 ########\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                images = images.view(-1, 3072)\n",
        "                \n",
        "                ################################\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "                \n",
        "                outputs = net(images)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss = val_loss / len(valloader)\n",
        "            val_acc = 100 * correct / total\n",
        "            \n",
        "        print('Epoch {}, Train Loss: {}, Val Loss: {}, Val Acc: {}'.format(epoch, train_loss, val_loss, val_acc ))\n",
        "\n",
        "\n",
        "    # ===== Evaluation ===== #\n",
        "    net.eval()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images = images.view(-1, 3072)\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "            \n",
        "    return train_loss, val_loss, val_acc , test_acc #: test_acc shoudn't be trained (either by machine, tester)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "omgExzmQgU1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Experiment"
      ]
    },
    {
      "metadata": {
        "id": "DRoOy_B3Wu7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5777
        },
        "outputId": "76e751ad-f345-4347-a024-faf04c9ed40a"
      },
      "cell_type": "code",
      "source": [
        "# ====== Grid Test ====== #\n",
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "\n",
        "args.n_layer = 5\n",
        "args.in_dim = 3072\n",
        "args.out_dim = 10\n",
        "args.hid_dim = 100\n",
        "args.act = 'relu'\n",
        "\n",
        "args.lr = 0.001\n",
        "args.mm = 0.9\n",
        "args.epoch = 3\n",
        "\n",
        "\n",
        "list_n_layer = [3, 4, 5, 6, 7]\n",
        "list_hid_dim = [100, 200, 400, 800]\n",
        "list_lr = [.1, .01, .001, .0001]\n",
        "\n",
        "results = {\"n_layer\":[], \"hid_dim\":[], \"lr\":[], \"train_loss\":[], \"val_loss\":[], \"val_acc\":[], \"test_acc\":[]}\n",
        "\n",
        "\n",
        "for var1 in list_n_layer:\n",
        "    for var2 in list_hid_dim:\n",
        "        for var3 in list_lr:\n",
        "            args.n_layer = var1\n",
        "            args.hid_dim = var2\n",
        "            args.lr = var3\n",
        "            result = experiment(args)\n",
        "            print(args.n_layer, args.hid_dim, args.lr, result[0:2])\n",
        "            results[\"n_layer\"].append(args.n_layer)\n",
        "            results[\"hid_dim\"].append(args.hid_dim)\n",
        "            results[\"lr\"].append(args.lr)\n",
        "            results[\"train_loss\"].append(result[0])\n",
        "            results[\"val_loss\"].append(result[1])\n",
        "            results[\"val_acc\"].append(result[2])\n",
        "            results[\"test_acc\"].append(result[3])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "3 100 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 21298.81070739031, Val Loss: 2.162953118801117, Val Acc: 16.74\n",
            "Epoch 1, Train Loss: 22707.860365509987, Val Loss: 2.271721113014221, Val Acc: 15.74\n",
            "Epoch 2, Train Loss: 22499.64016544819, Val Loss: 2.260210109233856, Val Acc: 14.29\n",
            "3 100 0.01 (22499.64016544819, 2.260210109233856)\n",
            "Epoch 0, Train Loss: 17729.019091129303, Val Loss: 1.5849751967787742, Val Acc: 43.4\n",
            "Epoch 1, Train Loss: 15226.626621723175, Val Loss: 1.5125966014266015, Val Acc: 46.02\n",
            "Epoch 2, Train Loss: 14188.57342851162, Val Loss: 1.4608655064344407, Val Acc: 48.43\n",
            "3 100 0.001 (14188.57342851162, 1.4608655064344407)\n",
            "Epoch 0, Train Loss: 21637.185064554214, Val Loss: 1.979131968808174, Val Acc: 28.53\n",
            "Epoch 1, Train Loss: 18558.14709532261, Val Loss: 1.7608481732845307, Val Acc: 36.38\n",
            "Epoch 2, Train Loss: 16931.22497320175, Val Loss: 1.650023266673088, Val Acc: 40.38\n",
            "3 100 0.0001 (16931.22497320175, 1.650023266673088)\n",
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "3 200 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 20521.264184951782, Val Loss: 2.163285489034653, Val Acc: 24.14\n",
            "Epoch 1, Train Loss: 21451.35184133053, Val Loss: 2.1583375613689424, Val Acc: 17.3\n",
            "Epoch 2, Train Loss: 23075.575804054737, Val Loss: 2.3062112793922425, Val Acc: 10.06\n",
            "3 200 0.01 (23075.575804054737, 2.3062112793922425)\n",
            "Epoch 0, Train Loss: 17428.756867319345, Val Loss: 1.5866174833655358, Val Acc: 43.6\n",
            "Epoch 1, Train Loss: 14874.261454194784, Val Loss: 1.459666105389595, Val Acc: 48.33\n",
            "Epoch 2, Train Loss: 13729.727224469185, Val Loss: 1.4346904076933862, Val Acc: 48.86\n",
            "3 200 0.001 (13729.727224469185, 1.4346904076933862)\n",
            "Epoch 0, Train Loss: 21629.150202035904, Val Loss: 1.9663555541992188, Val Acc: 28.28\n",
            "Epoch 1, Train Loss: 18525.99004250765, Val Loss: 1.7596467893600465, Val Acc: 36.77\n",
            "Epoch 2, Train Loss: 16895.853568315506, Val Loss: 1.644643288254738, Val Acc: 40.85\n",
            "3 200 0.0001 (16895.853568315506, 1.644643288254738)\n",
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "3 400 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 20182.194528609514, Val Loss: 2.019476099228859, Val Acc: 29.02\n",
            "Epoch 1, Train Loss: 21144.7869643569, Val Loss: 2.1168366840839385, Val Acc: 19.5\n",
            "Epoch 2, Train Loss: 21952.72668403387, Val Loss: 2.2279590792179107, Val Acc: 13.81\n",
            "3 400 0.01 (21952.72668403387, 2.2279590792179107)\n",
            "Epoch 0, Train Loss: 17322.014514118433, Val Loss: 1.57315775411129, Val Acc: 43.91\n",
            "Epoch 1, Train Loss: 14609.868480980396, Val Loss: 1.474898127746582, Val Acc: 47.71\n",
            "Epoch 2, Train Loss: 13383.9839912951, Val Loss: 1.4223138855457307, Val Acc: 49.05\n",
            "3 400 0.001 (13383.9839912951, 1.4223138855457307)\n",
            "Epoch 0, Train Loss: 21412.868368148804, Val Loss: 1.9390704603433608, Val Acc: 29.46\n",
            "Epoch 1, Train Loss: 18250.329959332943, Val Loss: 1.7442589669704438, Val Acc: 37.77\n",
            "Epoch 2, Train Loss: 16680.98278826475, Val Loss: 1.6310132695674897, Val Acc: 41.83\n",
            "3 400 0.0001 (16680.98278826475, 1.6310132695674897)\n",
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "3 800 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 20055.690769553185, Val Loss: 2.0562362159013747, Val Acc: 29.89\n",
            "Epoch 1, Train Loss: 20542.32591456175, Val Loss: 2.1683831704378127, Val Acc: 25.07\n",
            "Epoch 2, Train Loss: 21456.692949473858, Val Loss: 2.0874214545965195, Val Acc: 24.27\n",
            "3 800 0.01 (21456.692949473858, 2.0874214545965195)\n",
            "Epoch 0, Train Loss: 17183.370483070612, Val Loss: 1.527376537668705, Val Acc: 45.98\n",
            "Epoch 1, Train Loss: 14470.941470175982, Val Loss: 1.4429826391100884, Val Acc: 48.4\n",
            "Epoch 2, Train Loss: 13169.5106716156, Val Loss: 1.3749438899040223, Val Acc: 51.17\n",
            "3 800 0.001 (13169.5106716156, 1.3749438899040223)\n",
            "Epoch 0, Train Loss: 21311.682054579258, Val Loss: 1.9235392261743545, Val Acc: 31.19\n",
            "Epoch 1, Train Loss: 18060.102298796177, Val Loss: 1.7214773270845414, Val Acc: 38.37\n",
            "Epoch 2, Train Loss: 16470.455581843853, Val Loss: 1.605345023870468, Val Acc: 42.66\n",
            "3 800 0.0001 (16470.455581843853, 1.605345023870468)\n",
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "4 100 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 20063.6029946208, Val Loss: 2.057401724100113, Val Acc: 25.65\n",
            "Epoch 1, Train Loss: 21062.479528546333, Val Loss: 2.1260396529197694, Val Acc: 16.37\n",
            "Epoch 2, Train Loss: 22221.41210269928, Val Loss: 2.3044042172431944, Val Acc: 10.2\n",
            "4 100 0.01 (22221.41210269928, 2.3044042172431944)\n",
            "Epoch 0, Train Loss: 18597.018707752228, Val Loss: 1.6554744366645813, Val Acc: 40.8\n",
            "Epoch 1, Train Loss: 15581.296123504639, Val Loss: 1.53458596701622, Val Acc: 45.33\n",
            "Epoch 2, Train Loss: 14406.221928834915, Val Loss: 1.4555985825419426, Val Acc: 47.83\n",
            "4 100 0.001 (14406.221928834915, 1.4555985825419426)\n",
            "Epoch 0, Train Loss: 22810.051811933517, Val Loss: 2.203538938331604, Val Acc: 16.81\n",
            "Epoch 1, Train Loss: 20498.736671864986, Val Loss: 1.9432462920188904, Val Acc: 28.49\n",
            "Epoch 2, Train Loss: 18709.683070659637, Val Loss: 1.8145203829288483, Val Acc: 34.26\n",
            "4 100 0.0001 (18709.683070659637, 1.8145203829288483)\n",
            "Epoch 0, Train Loss: 23599.201248526573, Val Loss: 2.335996873521805, Val Acc: 10.01\n",
            "Epoch 1, Train Loss: 23588.443393349648, Val Loss: 2.3663624198913573, Val Acc: 9.86\n",
            "Epoch 2, Train Loss: 23591.612466096878, Val Loss: 2.34421477394104, Val Acc: 10.69\n",
            "4 200 0.1 (23591.612466096878, 2.34421477394104)\n",
            "Epoch 0, Train Loss: 19684.96886187792, Val Loss: 1.9248241756677626, Val Acc: 29.67\n",
            "Epoch 1, Train Loss: 20530.452420949936, Val Loss: 2.112667465353012, Val Acc: 24.41\n",
            "Epoch 2, Train Loss: 62665.399269878864, Val Loss: 2.3081980169296266, Val Acc: 9.54\n",
            "4 200 0.01 (62665.399269878864, 2.3081980169296266)\n",
            "Epoch 0, Train Loss: 18568.768587619066, Val Loss: 1.6068838988423348, Val Acc: 42.42\n",
            "Epoch 1, Train Loss: 15306.815884172916, Val Loss: 1.492452140057087, Val Acc: 46.91\n",
            "Epoch 2, Train Loss: 14051.745988935232, Val Loss: 1.46664160592556, Val Acc: 47.38\n",
            "4 200 0.001 (14051.745988935232, 1.46664160592556)\n",
            "Epoch 0, Train Loss: 22834.0792760849, Val Loss: 2.2156973962783812, Val Acc: 19.43\n",
            "Epoch 1, Train Loss: 20494.290989220142, Val Loss: 1.9233112159013748, Val Acc: 29.48\n",
            "Epoch 2, Train Loss: 18436.03568506241, Val Loss: 1.7767836394071579, Val Acc: 34.62\n",
            "4 200 0.0001 (18436.03568506241, 1.7767836394071579)\n",
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "4 400 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 19502.96099680662, Val Loss: 2.002064753127098, Val Acc: 29.55\n",
            "Epoch 1, Train Loss: 19683.12750914693, Val Loss: 2.0595453952550886, Val Acc: 28.08\n",
            "Epoch 2, Train Loss: 20436.61942523718, Val Loss: 1.9987397159337998, Val Acc: 27.62\n",
            "4 400 0.01 (20436.61942523718, 1.9987397159337998)\n",
            "Epoch 0, Train Loss: 18143.96693840623, Val Loss: 1.5909377042531967, Val Acc: 43.11\n",
            "Epoch 1, Train Loss: 15054.27789002657, Val Loss: 1.4770760388374329, Val Acc: 46.47\n",
            "Epoch 2, Train Loss: 13660.721957236528, Val Loss: 1.445176111125946, Val Acc: 47.85\n",
            "4 400 0.001 (13660.721957236528, 1.445176111125946)\n",
            "Epoch 0, Train Loss: 22765.859887242317, Val Loss: 2.183502195739746, Val Acc: 22.01\n",
            "Epoch 1, Train Loss: 20245.959614396095, Val Loss: 1.9082807163000106, Val Acc: 29.38\n",
            "Epoch 2, Train Loss: 18277.385251939297, Val Loss: 1.7601356959342958, Val Acc: 36.04\n",
            "4 400 0.0001 (18277.385251939297, 1.7601356959342958)\n",
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "4 800 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 19205.781695961952, Val Loss: 1.8483714884996414, Val Acc: 31.88\n",
            "Epoch 1, Train Loss: 18885.605988442898, Val Loss: 2.0471749209880827, Val Acc: 27.78\n",
            "Epoch 2, Train Loss: 19537.412669330835, Val Loss: 2.0059679858446122, Val Acc: 28.75\n",
            "4 800 0.01 (19537.412669330835, 2.0059679858446122)\n",
            "Epoch 0, Train Loss: 17978.932831048965, Val Loss: 1.610235464513302, Val Acc: 42.87\n",
            "Epoch 1, Train Loss: 14824.042599767447, Val Loss: 1.4746744817256927, Val Acc: 47.28\n",
            "Epoch 2, Train Loss: 13469.18523812294, Val Loss: 1.3983736798882485, Val Acc: 49.93\n",
            "4 800 0.001 (13469.18523812294, 1.3983736798882485)\n",
            "Epoch 0, Train Loss: 22642.928181409836, Val Loss: 2.140302189588547, Val Acc: 21.51\n",
            "Epoch 1, Train Loss: 19868.63491755724, Val Loss: 1.8694682518482209, Val Acc: 32.21\n",
            "Epoch 2, Train Loss: 17850.570196926594, Val Loss: 1.714577176141739, Val Acc: 38.04\n",
            "4 800 0.0001 (17850.570196926594, 1.714577176141739)\n",
            "Epoch 0, Train Loss: 23616.50257372856, Val Loss: 2.3600164633750915, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: 23602.631858825684, Val Loss: 2.327486514377594, Val Acc: 10.24\n",
            "Epoch 2, Train Loss: 23596.17986059189, Val Loss: 2.3476208085536956, Val Acc: 9.86\n",
            "5 100 0.1 (23596.17986059189, 2.3476208085536956)\n",
            "Epoch 0, Train Loss: 19812.457804501057, Val Loss: 1.9164131282091141, Val Acc: 31.13\n",
            "Epoch 1, Train Loss: 20254.05512934923, Val Loss: 2.2867295441150666, Val Acc: 16.93\n",
            "Epoch 2, Train Loss: 23028.979139447212, Val Loss: 2.3115194931983947, Val Acc: 9.86\n",
            "5 100 0.01 (23028.979139447212, 2.3115194931983947)\n",
            "Epoch 0, Train Loss: 19919.094226419926, Val Loss: 1.7003341079235077, Val Acc: 38.33\n",
            "Epoch 1, Train Loss: 16167.404312312603, Val Loss: 1.5462213389396668, Val Acc: 43.94\n",
            "Epoch 2, Train Loss: 14824.255001723766, Val Loss: 1.5059795812249184, Val Acc: 45.86\n",
            "5 100 0.001 (14824.255001723766, 1.5059795812249184)\n",
            "Epoch 0, Train Loss: 23019.66203403473, Val Loss: 2.2997857268333437, Val Acc: 13.55\n",
            "Epoch 1, Train Loss: 22926.234694957733, Val Loss: 2.2749014784812926, Val Acc: 20.68\n",
            "Epoch 2, Train Loss: 21621.25753378868, Val Loss: 2.0468164385318754, Val Acc: 22.11\n",
            "5 100 0.0001 (21621.25753378868, 2.0468164385318754)\n",
            "Epoch 0, Train Loss: 23592.137511491776, Val Loss: 2.321147599220276, Val Acc: 9.85\n",
            "Epoch 1, Train Loss: 23588.733539819717, Val Loss: 2.376869410276413, Val Acc: 9.79\n",
            "Epoch 2, Train Loss: 23573.29731655121, Val Loss: 2.359323671960831, Val Acc: 10.13\n",
            "5 200 0.1 (23573.29731655121, 2.359323671960831)\n",
            "Epoch 0, Train Loss: 19624.95959663391, Val Loss: 1.9503986299991607, Val Acc: 28.54\n",
            "Epoch 1, Train Loss: 19149.348004698753, Val Loss: 1.9632039393901826, Val Acc: 31.09\n",
            "Epoch 2, Train Loss: 20097.51604050398, Val Loss: 2.066693361186981, Val Acc: 22.15\n",
            "5 200 0.01 (20097.51604050398, 2.066693361186981)\n",
            "Epoch 0, Train Loss: 19345.71496295929, Val Loss: 1.6656635917186737, Val Acc: 39.81\n",
            "Epoch 1, Train Loss: 15754.58619916439, Val Loss: 1.5095993975520134, Val Acc: 45.87\n",
            "Epoch 2, Train Loss: 14349.810010582209, Val Loss: 1.4838517536759377, Val Acc: 47.5\n",
            "5 200 0.001 (14349.810010582209, 1.4838517536759377)\n",
            "Epoch 0, Train Loss: 22997.029623031616, Val Loss: 2.294080842590332, Val Acc: 17.74\n",
            "Epoch 1, Train Loss: 22494.253328084946, Val Loss: 2.1295172975063323, Val Acc: 17.15\n",
            "Epoch 2, Train Loss: 20318.724375724792, Val Loss: 1.9489712717533112, Val Acc: 26.84\n",
            "5 200 0.0001 (20318.724375724792, 1.9489712717533112)\n",
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "5 400 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 19370.80906277895, Val Loss: 1.8663278327941895, Val Acc: 32.3\n",
            "Epoch 1, Train Loss: 18611.479407131672, Val Loss: 1.8103543543577194, Val Acc: 35.04\n",
            "Epoch 2, Train Loss: 19110.512543022633, Val Loss: 1.996564804649353, Val Acc: 27.82\n",
            "5 400 0.01 (19110.512543022633, 1.996564804649353)\n",
            "Epoch 0, Train Loss: 19112.098389685154, Val Loss: 1.6525007388830184, Val Acc: 40.46\n",
            "Epoch 1, Train Loss: 15536.757756143808, Val Loss: 1.4799322722911834, Val Acc: 47.32\n",
            "Epoch 2, Train Loss: 14151.429956257343, Val Loss: 1.431563703930378, Val Acc: 49.2\n",
            "5 400 0.001 (14151.429956257343, 1.431563703930378)\n",
            "Epoch 0, Train Loss: 23009.712695598602, Val Loss: 2.2982194452285767, Val Acc: 15.77\n",
            "Epoch 1, Train Loss: 22834.639894247055, Val Loss: 2.2405465041160584, Val Acc: 19.4\n",
            "Epoch 2, Train Loss: 20938.806746959686, Val Loss: 1.991066874074936, Val Acc: 25.85\n",
            "5 400 0.0001 (20938.806746959686, 1.991066874074936)\n",
            "Epoch 0, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 1, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: nan, Val Loss: nan, Val Acc: 10.69\n",
            "5 800 0.1 (nan, nan)\n",
            "Epoch 0, Train Loss: 19280.197131991386, Val Loss: 1.8352881245613097, Val Acc: 33.5\n",
            "Epoch 1, Train Loss: 18243.585220843554, Val Loss: 1.7637911021113395, Val Acc: 38.82\n",
            "Epoch 2, Train Loss: 18407.387925744057, Val Loss: 1.8620146719694137, Val Acc: 31.52\n",
            "5 800 0.01 (18407.387925744057, 1.8620146719694137)\n",
            "Epoch 0, Train Loss: 19064.543670773506, Val Loss: 1.6796975127220153, Val Acc: 39.38\n",
            "Epoch 1, Train Loss: 15360.914897173643, Val Loss: 1.490295191657543, Val Acc: 46.3\n",
            "Epoch 2, Train Loss: 13891.404279470444, Val Loss: 1.4165275832653046, Val Acc: 49.7\n",
            "5 800 0.001 (13891.404279470444, 1.4165275832653046)\n",
            "Epoch 0, Train Loss: 22999.88066959381, Val Loss: 2.29496733083725, Val Acc: 18.97\n",
            "Epoch 1, Train Loss: 22510.64745092392, Val Loss: 2.1267924207687376, Val Acc: 20.78\n",
            "Epoch 2, Train Loss: 20194.268821835518, Val Loss: 1.93243196413517, Val Acc: 27.49\n",
            "5 800 0.0001 (20194.268821835518, 1.93243196413517)\n",
            "Epoch 0, Train Loss: 23591.870079159737, Val Loss: 2.381750591373444, Val Acc: 9.79\n",
            "Epoch 1, Train Loss: 23603.45369899273, Val Loss: 2.3402181948184966, Val Acc: 9.72\n",
            "Epoch 2, Train Loss: 23583.350367307663, Val Loss: 2.349550431871414, Val Acc: 9.54\n",
            "6 100 0.1 (23583.350367307663, 2.349550431871414)\n",
            "Epoch 0, Train Loss: 20046.007242321968, Val Loss: 1.8933559439182281, Val Acc: 27.47\n",
            "Epoch 1, Train Loss: 19330.851810902357, Val Loss: 2.237393267798424, Val Acc: 26.15\n",
            "Epoch 2, Train Loss: 20824.79002338648, Val Loss: 2.1845436974048615, Val Acc: 16.14\n",
            "6 100 0.01 (20824.79002338648, 2.1845436974048615)\n",
            "Epoch 0, Train Loss: 20809.389846503735, Val Loss: 1.8221127747535706, Val Acc: 31.51\n",
            "Epoch 1, Train Loss: 16914.789800077677, Val Loss: 1.598456459569931, Val Acc: 41.83\n",
            "Epoch 2, Train Loss: 15322.45124283433, Val Loss: 1.5252818548560143, Val Acc: 45.04\n",
            "6 100 0.001 (15322.45124283433, 1.5252818548560143)\n",
            "Epoch 0, Train Loss: 23030.091686964035, Val Loss: 2.3023493735313414, Val Acc: 10.04\n",
            "Epoch 1, Train Loss: 23014.178061008453, Val Loss: 2.3006945946693422, Val Acc: 14.2\n",
            "Epoch 2, Train Loss: 22977.474420309067, Val Loss: 2.292877427482605, Val Acc: 17.51\n",
            "6 100 0.0001 (22977.474420309067, 2.292877427482605)\n",
            "Epoch 0, Train Loss: 23591.23909318447, Val Loss: 2.3505348763465883, Val Acc: 9.79\n",
            "Epoch 1, Train Loss: 23598.856820702553, Val Loss: 2.381052999830246, Val Acc: 10.13\n",
            "Epoch 2, Train Loss: 23581.771301984787, Val Loss: 2.3548221245765686, Val Acc: 10.13\n",
            "6 200 0.1 (23581.771301984787, 2.3548221245765686)\n",
            "Epoch 0, Train Loss: 19948.372652620077, Val Loss: 1.889033195400238, Val Acc: 29.19\n",
            "Epoch 1, Train Loss: 19024.838332116604, Val Loss: 1.8884529298782349, Val Acc: 30.14\n",
            "Epoch 2, Train Loss: 19296.91522604227, Val Loss: 1.9616680244922637, Val Acc: 28.25\n",
            "6 200 0.01 (19296.91522604227, 1.9616680244922637)\n",
            "Epoch 0, Train Loss: 21184.134637475014, Val Loss: 1.8557023456811905, Val Acc: 31.76\n",
            "Epoch 1, Train Loss: 16938.1866992414, Val Loss: 1.6040865600705148, Val Acc: 41.98\n",
            "Epoch 2, Train Loss: 15109.565587252378, Val Loss: 1.5015870401501656, Val Acc: 45.74\n",
            "6 200 0.001 (15109.565587252378, 1.5015870401501656)\n",
            "Epoch 0, Train Loss: 23027.66590976715, Val Loss: 2.302013296222687, Val Acc: 10.43\n",
            "Epoch 1, Train Loss: 23015.44070649147, Val Loss: 2.3008511631965636, Val Acc: 14.26\n",
            "Epoch 2, Train Loss: 22986.02626991272, Val Loss: 2.2945399651527403, Val Acc: 16.24\n",
            "6 200 0.0001 (22986.02626991272, 2.2945399651527403)\n",
            "Epoch 0, Train Loss: 23581.387439608574, Val Loss: 2.328122336578369, Val Acc: 10.17\n",
            "Epoch 1, Train Loss: 23599.5998595953, Val Loss: 2.4050565474510193, Val Acc: 10.01\n",
            "Epoch 2, Train Loss: 23600.15824496746, Val Loss: 2.4163148858070373, Val Acc: 9.54\n",
            "6 400 0.1 (23600.15824496746, 2.4163148858070373)\n",
            "Epoch 0, Train Loss: 19843.645608246326, Val Loss: 1.8787267016172409, Val Acc: 29.12\n",
            "Epoch 1, Train Loss: 18576.316539674997, Val Loss: 1.8289529637098312, Val Acc: 32.06\n",
            "Epoch 2, Train Loss: 18548.11128282547, Val Loss: 1.9045559720039367, Val Acc: 29.2\n",
            "6 400 0.01 (18548.11128282547, 1.9045559720039367)\n",
            "Epoch 0, Train Loss: 21150.892009854317, Val Loss: 1.8512483843564986, Val Acc: 31.49\n",
            "Epoch 1, Train Loss: 16772.32860723138, Val Loss: 1.570754224395752, Val Acc: 43.3\n",
            "Epoch 2, Train Loss: 14931.948078542948, Val Loss: 1.5251218676924705, Val Acc: 45.15\n",
            "6 400 0.001 (14931.948078542948, 1.5251218676924705)\n",
            "Epoch 0, Train Loss: 23024.736334085464, Val Loss: 2.3022464567184446, Val Acc: 11.45\n",
            "Epoch 1, Train Loss: 23015.072516918182, Val Loss: 2.3009864367485044, Val Acc: 9.54\n",
            "Epoch 2, Train Loss: 22991.692224740982, Val Loss: 2.2962069222450254, Val Acc: 17.13\n",
            "6 400 0.0001 (22991.692224740982, 2.2962069222450254)\n",
            "Epoch 0, Train Loss: 23610.465165376663, Val Loss: 2.347201551961899, Val Acc: 9.72\n",
            "Epoch 1, Train Loss: 23607.218332767487, Val Loss: 2.332401698732376, Val Acc: 10.69\n",
            "Epoch 2, Train Loss: 23604.398102760315, Val Loss: 2.3625375208377837, Val Acc: 10.13\n",
            "6 800 0.1 (23604.398102760315, 2.3625375208377837)\n",
            "Epoch 0, Train Loss: 19700.165080308914, Val Loss: 1.880259051823616, Val Acc: 30.34\n",
            "Epoch 1, Train Loss: 18417.190978705883, Val Loss: 1.790332306933403, Val Acc: 34.27\n",
            "Epoch 2, Train Loss: 18102.2542450428, Val Loss: 1.9963967114210128, Val Acc: 33.18\n",
            "6 800 0.01 (18102.2542450428, 1.9963967114210128)\n",
            "Epoch 0, Train Loss: 20563.250039577484, Val Loss: 1.7668486012935638, Val Acc: 33.52\n",
            "Epoch 1, Train Loss: 16343.88622558117, Val Loss: 1.5588320666790008, Val Acc: 43.69\n",
            "Epoch 2, Train Loss: 14637.034951597452, Val Loss: 1.4709495942950248, Val Acc: 46.83\n",
            "6 800 0.001 (14637.034951597452, 1.4709495942950248)\n",
            "Epoch 0, Train Loss: 23023.726557970047, Val Loss: 2.3016616057395933, Val Acc: 12.21\n",
            "Epoch 1, Train Loss: 23006.685089588165, Val Loss: 2.299166257572174, Val Acc: 17.52\n",
            "Epoch 2, Train Loss: 22919.006119966507, Val Loss: 2.2725277344703674, Val Acc: 17.83\n",
            "6 800 0.0001 (22919.006119966507, 2.2725277344703674)\n",
            "Epoch 0, Train Loss: 23600.979819059372, Val Loss: 2.341541120529175, Val Acc: 9.85\n",
            "Epoch 1, Train Loss: 23603.57708275318, Val Loss: 2.371335426902771, Val Acc: 10.24\n",
            "Epoch 2, Train Loss: 23611.0627245903, Val Loss: 2.3525491433143615, Val Acc: 10.17\n",
            "7 100 0.1 (23611.0627245903, 2.3525491433143615)\n",
            "Epoch 0, Train Loss: 20551.623777091503, Val Loss: 2.0023302427768708, Val Acc: 24.28\n",
            "Epoch 1, Train Loss: 19509.215164601803, Val Loss: 1.9848058792829513, Val Acc: 29.06\n",
            "Epoch 2, Train Loss: 20418.431744277477, Val Loss: 2.0953722637176515, Val Acc: 20.06\n",
            "7 100 0.01 (20418.431744277477, 2.0953722637176515)\n",
            "Epoch 0, Train Loss: 22401.903629422188, Val Loss: 2.0190091157913206, Val Acc: 18.57\n",
            "Epoch 1, Train Loss: 19219.281155586243, Val Loss: 1.8052020081996918, Val Acc: 31.28\n",
            "Epoch 2, Train Loss: 16997.871618181467, Val Loss: 1.6453778610944747, Val Acc: 39.44\n",
            "7 100 0.001 (16997.871618181467, 1.6453778610944747)\n",
            "Epoch 0, Train Loss: 23040.19533443451, Val Loss: 2.3025168776512146, Val Acc: 10.17\n",
            "Epoch 1, Train Loss: 23026.065717935562, Val Loss: 2.3024291828155516, Val Acc: 9.54\n",
            "Epoch 2, Train Loss: 23023.450812339783, Val Loss: 2.302312273311615, Val Acc: 9.54\n",
            "7 100 0.0001 (23023.450812339783, 2.302312273311615)\n",
            "Epoch 0, Train Loss: 23612.452364325523, Val Loss: 2.420865259218216, Val Acc: 9.72\n",
            "Epoch 1, Train Loss: 23600.14895117283, Val Loss: 2.393665618181229, Val Acc: 9.85\n",
            "Epoch 2, Train Loss: 23589.924639105797, Val Loss: 2.336977252483368, Val Acc: 10.13\n",
            "7 200 0.1 (23589.924639105797, 2.336977252483368)\n",
            "Epoch 0, Train Loss: 20845.408339500427, Val Loss: 1.9196577169179916, Val Acc: 27.29\n",
            "Epoch 1, Train Loss: 19268.310885846615, Val Loss: 1.9180902609586716, Val Acc: 26.58\n",
            "Epoch 2, Train Loss: 19200.705842524767, Val Loss: 1.8859034858703614, Val Acc: 29.37\n",
            "7 200 0.01 (19200.705842524767, 1.8859034858703614)\n",
            "Epoch 0, Train Loss: 22559.719517350197, Val Loss: 2.0338540837287904, Val Acc: 18.99\n",
            "Epoch 1, Train Loss: 19199.9531545043, Val Loss: 1.776666781926155, Val Acc: 32.91\n",
            "Epoch 2, Train Loss: 16789.098797678947, Val Loss: 1.6768729143857957, Val Acc: 39.61\n",
            "7 200 0.001 (16789.098797678947, 1.6768729143857957)\n",
            "Epoch 0, Train Loss: 23028.116027116776, Val Loss: 2.3025846442222595, Val Acc: 9.86\n",
            "Epoch 1, Train Loss: 23025.599124908447, Val Loss: 2.30268400554657, Val Acc: 12.46\n",
            "Epoch 2, Train Loss: 23024.715709209442, Val Loss: 2.3026528265953066, Val Acc: 9.72\n",
            "7 200 0.0001 (23024.715709209442, 2.3026528265953066)\n",
            "Epoch 0, Train Loss: 23577.351311445236, Val Loss: 2.3572978729724885, Val Acc: 10.24\n",
            "Epoch 1, Train Loss: 23591.503484249115, Val Loss: 2.3761680665016174, Val Acc: 10.13\n",
            "Epoch 2, Train Loss: 23607.64966416359, Val Loss: 2.3574754809856415, Val Acc: 9.72\n",
            "7 400 0.1 (23607.64966416359, 2.3574754809856415)\n",
            "Epoch 0, Train Loss: 20341.265023589134, Val Loss: 1.8612192661523819, Val Acc: 28.28\n",
            "Epoch 1, Train Loss: 18894.427537441254, Val Loss: 1.9360343473911286, Val Acc: 27.34\n",
            "Epoch 2, Train Loss: 18811.068345427513, Val Loss: 1.9183219082355498, Val Acc: 31.03\n",
            "7 400 0.01 (18811.068345427513, 1.9183219082355498)\n",
            "Epoch 0, Train Loss: 21996.538274526596, Val Loss: 1.9991947784900665, Val Acc: 17.91\n",
            "Epoch 1, Train Loss: 18446.889601528645, Val Loss: 1.7320825925111771, Val Acc: 35.13\n",
            "Epoch 2, Train Loss: 15945.977253317833, Val Loss: 1.550223154592514, Val Acc: 43.59\n",
            "7 400 0.001 (15945.977253317833, 1.550223154592514)\n",
            "Epoch 0, Train Loss: 23027.47510433197, Val Loss: 2.302779498767853, Val Acc: 9.79\n",
            "Epoch 1, Train Loss: 23025.29117155075, Val Loss: 2.3026503405570984, Val Acc: 10.86\n",
            "Epoch 2, Train Loss: 23023.72780919075, Val Loss: 2.3024980313301087, Val Acc: 9.54\n",
            "7 400 0.0001 (23023.72780919075, 2.3024980313301087)\n",
            "Epoch 0, Train Loss: 23598.683709025383, Val Loss: 2.3258755539894103, Val Acc: 10.17\n",
            "Epoch 1, Train Loss: 23579.643607020378, Val Loss: 2.3660228711605074, Val Acc: 9.86\n",
            "Epoch 2, Train Loss: 23599.523171186447, Val Loss: 2.3566891730308535, Val Acc: 9.72\n",
            "7 800 0.1 (23599.523171186447, 2.3566891730308535)\n",
            "Epoch 0, Train Loss: 20222.35110884905, Val Loss: 1.9242224719524383, Val Acc: 25.64\n",
            "Epoch 1, Train Loss: 18744.12134939432, Val Loss: 1.877666629266739, Val Acc: 33.46\n",
            "Epoch 2, Train Loss: 18460.221004009247, Val Loss: 1.8563194213628769, Val Acc: 30.81\n",
            "7 800 0.01 (18460.221004009247, 1.8563194213628769)\n",
            "Epoch 0, Train Loss: 22048.05404663086, Val Loss: 2.036552120089531, Val Acc: 21.56\n",
            "Epoch 1, Train Loss: 18126.634639561176, Val Loss: 1.7096370562314986, Val Acc: 36.02\n",
            "Epoch 2, Train Loss: 15860.563639611006, Val Loss: 1.5147187076091766, Val Acc: 45.7\n",
            "7 800 0.001 (15860.563639611006, 1.5147187076091766)\n",
            "Epoch 0, Train Loss: 23026.543578863144, Val Loss: 2.3025884479522705, Val Acc: 10.21\n",
            "Epoch 1, Train Loss: 23024.456008672714, Val Loss: 2.30252078666687, Val Acc: 10.61\n",
            "Epoch 2, Train Loss: 23022.054835796356, Val Loss: 2.302191352367401, Val Acc: 13.8\n",
            "7 800 0.0001 (23022.054835796356, 2.302191352367401)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mhs0GTef7Dyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "fa812bdb-a36f-479f-f738-6f32d1097c1d"
      },
      "cell_type": "code",
      "source": [
        "# ====== Random Test ====== #\n",
        "args.n_layer = 5\n",
        "args.in_dim = 3072\n",
        "args.out_dim = 10\n",
        "args.hid_dim = 100\n",
        "args.act = 'relu'\n",
        "\n",
        "args.lr = 0.001\n",
        "args.mm = 0.9\n",
        "args.epoch = 5\n",
        "\n",
        "for _ in range(10):\n",
        "    var1 = np.random.randint(2, 10)\n",
        "    var2 = 2 ** np.random.randint(3, 10)\n",
        "    var3 = .1 ** np.random.randint(1, 5)\n",
        "    args.n_layer = var1\n",
        "    args.hid_dim = var2\n",
        "    args.lr = var3\n",
        "    result = experiment(args)\n",
        "    print(var1, var2, var3, result)\n",
        "    list_result.append((var1, var2, var3, result))\n",
        "    results[\"n_layer\"].append(args.n_layer)\n",
        "    results[\"hid_dim\"].append(args.hid_dim)\n",
        "    results[\"lr\"].append(args.lr)\n",
        "    results[\"train_loss\"].append(result[0])\n",
        "    results[\"val_loss\"].append(result[1])\n",
        "    results[\"val_acc\"].append(result[2])\n",
        "    results[\"test_acc\"].append(result[3])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Train Loss: 23034.317021131516, Val Loss: 2.3025724511146546, Val Acc: 10.13\n",
            "Epoch 1, Train Loss: 21641.941073656082, Val Loss: 1.9992116573810577, Val Acc: 20.43\n",
            "Epoch 2, Train Loss: 19351.123461008072, Val Loss: 1.8401921659469604, Val Acc: 29.48\n",
            "Epoch 3, Train Loss: 16993.30404508114, Val Loss: 1.6050382831573486, Val Acc: 40.91\n",
            "Epoch 4, Train Loss: 15336.870354741812, Val Loss: 1.5104494742512702, Val Acc: 45.05\n",
            "8 256 0.0010000000000000002 (15336.870354741812, 1.5104494742512702, 45.05, 46.37)\n",
            "Epoch 0, Train Loss: 18340.46972501278, Val Loss: 1.6119767166733743, Val Acc: 42.07\n",
            "Epoch 1, Train Loss: 15420.32874301076, Val Loss: 1.5116655302286148, Val Acc: 46.28\n",
            "Epoch 2, Train Loss: 14201.861329227686, Val Loss: 1.4737717979073524, Val Acc: 48.42\n",
            "Epoch 3, Train Loss: 13419.708039939404, Val Loss: 1.4292302593588828, Val Acc: 49.9\n",
            "Epoch 4, Train Loss: 12732.226737588644, Val Loss: 1.3948483634114266, Val Acc: 50.85\n",
            "4 128 0.0010000000000000002 (12732.226737588644, 1.3948483634114266, 50.85, 50.17)\n",
            "Epoch 0, Train Loss: 23067.66413807869, Val Loss: 2.303271585273743, Val Acc: 9.85\n",
            "Epoch 1, Train Loss: 23029.89359855652, Val Loss: 2.302784320926666, Val Acc: 9.54\n",
            "Epoch 2, Train Loss: 23027.090574026108, Val Loss: 2.30276985912323, Val Acc: 9.54\n",
            "Epoch 3, Train Loss: 23026.73909163475, Val Loss: 2.302890295791626, Val Acc: 9.72\n",
            "Epoch 4, Train Loss: 23026.918224811554, Val Loss: 2.302914940547943, Val Acc: 9.54\n",
            "8 16 0.00010000000000000002 (23026.918224811554, 2.302914940547943, 9.54, 10.0)\n",
            "Epoch 0, Train Loss: 20422.786278545856, Val Loss: 2.1474478958129883, Val Acc: 19.64\n",
            "Epoch 1, Train Loss: 22567.80931162834, Val Loss: 2.307307780456543, Val Acc: 9.87\n",
            "Epoch 2, Train Loss: 22905.885138869286, Val Loss: 2.170121081209183, Val Acc: 16.08\n",
            "Epoch 3, Train Loss: 22900.292411088943, Val Loss: 2.3063783871650694, Val Acc: 9.86\n",
            "Epoch 4, Train Loss: 23082.689247131348, Val Loss: 2.3090304350852966, Val Acc: 9.79\n",
            "4 64 0.010000000000000002 (23082.689247131348, 2.3090304350852966, 9.79, 10.0)\n",
            "Epoch 0, Train Loss: 23609.082040786743, Val Loss: 2.3660714155197144, Val Acc: 9.79\n",
            "Epoch 1, Train Loss: 23586.772535085678, Val Loss: 2.345628497314453, Val Acc: 10.13\n",
            "Epoch 2, Train Loss: 23601.92287194729, Val Loss: 2.3207513594627383, Val Acc: 10.13\n",
            "Epoch 3, Train Loss: 23592.80043053627, Val Loss: 2.3982000669956207, Val Acc: 9.72\n",
            "Epoch 4, Train Loss: 23598.463805794716, Val Loss: 2.3389105289936065, Val Acc: 10.17\n",
            "8 16 0.1 (23598.463805794716, 2.3389105289936065, 10.17, 10.0)\n",
            "Epoch 0, Train Loss: 21396.470776438713, Val Loss: 1.932607418870926, Val Acc: 30.65\n",
            "Epoch 1, Train Loss: 18172.238878965378, Val Loss: 1.7326112499952315, Val Acc: 37.86\n",
            "Epoch 2, Train Loss: 16600.66938686371, Val Loss: 1.624417030310631, Val Acc: 41.5\n",
            "Epoch 3, Train Loss: 15579.266221642494, Val Loss: 1.5476117896676063, Val Acc: 44.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aDlgq30B43R0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ====== Grid & Random Visualization ====== #\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10), projection=\"3d\")\n",
        "plt.scatter(results[\"n_layer\"], results[\"hid_dim\"], results[\"lr\"], c=results[\"val_acc\"])\n",
        "\n",
        "plt.set_xlabel('n_layer')\n",
        "plt.set_ylabel('hid_dim')\n",
        "plt.set_zlabel('lr')\n",
        "plt.set_title('Hyperparameter Train Set Distribution')\n",
        "plt.set_zlim(-10, 6)\n",
        "plt.view_init(40, -60)\n",
        "plt.invert_xaxis()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BOY9Pocu-Otd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ====== Hand Tuning Test ====== #\n",
        "\n",
        "args.n_layer = 5\n",
        "args.in_dim = 3072\n",
        "args.out_dim = 10\n",
        "args.hid_dim = 100\n",
        "args.act = 'relu'\n",
        "\n",
        "args.lr = 0.001\n",
        "args.mm = 0.9\n",
        "args.epoch = 5\n",
        "\n",
        "for _ in range(10):\n",
        "    var1 = int(input())\n",
        "    var2 = int(input())\n",
        "    args.n_layer = var1\n",
        "    args.hid_dim = var2\n",
        "    result = experiment(args)\n",
        "    print(var1, var2, result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}